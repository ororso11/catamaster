"""
ê°œì„ ëœ PDF ì œí’ˆ ì¶”ì¶œê¸°:
1. Google Vision API í™˜ê²½ ë³€ìˆ˜ ì§€ì›
2. ì¤‘ë³µ ì œê±° ê°•í™”
3. ì „ë°©í–¥ í…ìŠ¤íŠ¸ íƒìƒ‰
"""

import io
import base64
from PIL import Image, ImageDraw
import fitz
import os
import re
import json

class ImageExtractor:
    def __init__(self):
        self.use_vision = False
        try:
            from google.cloud import vision
            
            # í™˜ê²½ ë³€ìˆ˜ì—ì„œ JSON ì½ê¸° (Railway ë°°í¬ìš©)
            credentials_json = os.environ.get('GOOGLE_APPLICATION_CREDENTIALS_JSON')
            if credentials_json:
                print("ğŸ“Œ í™˜ê²½ ë³€ìˆ˜ì—ì„œ Google Vision ì¸ì¦ ì •ë³´ ë¡œë“œ ì¤‘...")
                # JSONì„ ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥
                credentials_path = '/tmp/google-credentials.json'
                with open(credentials_path, 'w') as f:
                    f.write(credentials_json)
                os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = credentials_path
                print("âœ“ í™˜ê²½ ë³€ìˆ˜ì—ì„œ ì¸ì¦ ì •ë³´ ë¡œë“œ ì™„ë£Œ")
            elif os.path.exists('google-vision-key.json'):
                print("ğŸ“Œ ë¡œì»¬ íŒŒì¼ì—ì„œ Google Vision ì¸ì¦ ì •ë³´ ë¡œë“œ ì¤‘...")
                os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = 'google-vision-key.json'
                print("âœ“ ë¡œì»¬ íŒŒì¼ì—ì„œ ì¸ì¦ ì •ë³´ ë¡œë“œ ì™„ë£Œ")
            else:
                print("âš ï¸ Google Vision ì¸ì¦ íŒŒì¼ ì—†ìŒ")
                raise Exception("No credentials found")
            
            self.vision_client = vision.ImageAnnotatorClient()
            self.use_vision = True
            print("âœ“ Google Vision API í™œì„±í™”ë¨\n")
            
        except Exception as e:
            print(f"âœ— Google Vision API ë¹„í™œì„±í™”: {str(e)}\n")
            self.use_vision = False
    
    def extract_from_pdf(self, pdf_bytes):
        results = []
        
        try:
            pdf_document = fitz.open(stream=pdf_bytes, filetype="pdf")
            total_pages = len(pdf_document)
            print(f"\n{'='*80}")
            print(f"ğŸ“„ ì´ {total_pages}ê°œ í˜ì´ì§€ ì²˜ë¦¬ ì‹œì‘")
            print(f"{'='*80}\n")
            
            # Vision API í˜¸ì¶œ
            all_pages_text_data = None
            if self.use_vision:
                print("ğŸ” Google Vision OCR ì‹¤í–‰ ì¤‘...\n")
                all_pages_text_data = self._extract_all_text_once(pdf_document)
                print("âœ“ OCR ì™„ë£Œ\n")
            else:
                print("âš ï¸ Vision API ì—†ì´ ì§„í–‰ - ì œí’ˆëª… ì¶”ì¶œ ì œí•œì \n")
            
            for page_num in range(total_pages):
                print(f"\n{'='*80}")
                print(f"ğŸ“– í˜ì´ì§€ {page_num + 1}/{total_pages}")
                print(f"{'='*80}\n")
                
                page = pdf_document[page_num]
                
                zoom = 2.0
                mat = fitz.Matrix(zoom, zoom)
                pix = page.get_pixmap(matrix=mat)
                page_img_bytes = pix.tobytes("png")
                page_width = pix.width
                page_height = pix.height
                
                text_blocks = []
                if all_pages_text_data and page_num in all_pages_text_data:
                    text_blocks = all_pages_text_data[page_num]
                    print(f"ğŸ“ ì¶”ì¶œëœ í…ìŠ¤íŠ¸ ë¸”ë¡: {len(text_blocks)}ê°œ\n")
                
                debug_image = self._create_text_visualization(page_img_bytes, text_blocks)
                
                products = self._extract_with_position_matching(
                    page, pdf_document, text_blocks, page_width, page_height
                )
                
                print(f"\nâœ… {len(products)}ê°œ ì œí’ˆ ì¶”ì¶œ ì™„ë£Œ")
                print(f"{'-'*80}")
                for i, p in enumerate(products, 1):
                    print(f"\nì œí’ˆ {i}:")
                    print(f"  ì´ë¦„: {p['name']}")
                    if p['specs']:
                        print(f"  ìŠ¤í™: {', '.join(p['specs'][:3])}")
                print(f"{'-'*80}\n")
                
                page_pil = Image.open(io.BytesIO(page_img_bytes))
                page_image = self._image_to_base64(page_pil)
                
                results.append({
                    'page': page_num + 1,
                    'type': 'list',
                    'image': page_image,
                    'debug_image': debug_image,
                    'products': products,
                    'text_blocks_count': len(text_blocks)
                })
            
            pdf_document.close()
            print(f"\n{'='*80}")
            print(f"âœ… ì „ì²´ ì²˜ë¦¬ ì™„ë£Œ!")
            print(f"{'='*80}\n")
            return results
            
        except Exception as e:
            print(f"\nâŒ ì˜¤ë¥˜ ë°œìƒ: {str(e)}\n")
            import traceback
            traceback.print_exc()
            raise
    
    def _create_text_visualization(self, page_img_bytes, text_blocks):
        try:
            img = Image.open(io.BytesIO(page_img_bytes)).convert('RGB')
            draw = ImageDraw.Draw(img)
            
            for block in text_blocks:
                x, y, w, h = block['x'], block['y'], block['w'], block['h']
                draw.rectangle([x, y, x+w, y+h], outline='red', width=2)
                try:
                    text = block['text'][:15]
                    draw.text((x, max(0, y-15)), text, fill='blue')
                except:
                    pass
            
            return self._image_to_base64(img)
        except:
            return None
    
    def _extract_all_text_once(self, pdf_document):
        try:
            from google.cloud import vision
            
            all_text_data = {}
            
            for page_num in range(len(pdf_document)):
                page = pdf_document[page_num]
                
                zoom = 2.0
                mat = fitz.Matrix(zoom, zoom)
                pix = page.get_pixmap(matrix=mat)
                img_bytes = pix.tobytes("png")
                
                vision_image = vision.Image(content=img_bytes)
                response = self.vision_client.text_detection(image=vision_image)
                
                texts = response.text_annotations
                if not texts:
                    all_text_data[page_num] = []
                    continue
                
                print(f"í˜ì´ì§€ {page_num + 1} OCR ì „ì²´ í…ìŠ¤íŠ¸:")
                print(f"{'-'*60}")
                print(texts[0].description[:500])
                print(f"{'-'*60}\n")
                
                text_blocks = []
                for text in texts[1:]:
                    vertices = text.bounding_poly.vertices
                    x = min(v.x for v in vertices)
                    y = min(v.y for v in vertices)
                    w = max(v.x for v in vertices) - x
                    h = max(v.y for v in vertices) - y
                    
                    text_blocks.append({
                        'text': text.description,
                        'x': x,
                        'y': y,
                        'w': w,
                        'h': h,
                        'center_x': x + w/2,
                        'center_y': y + h/2
                    })
                
                all_text_data[page_num] = text_blocks
            
            return all_text_data
            
        except Exception as e:
            print(f"âŒ Vision OCR ì˜¤ë¥˜: {e}\n")
            import traceback
            traceback.print_exc()
            return {}
    
    def _extract_with_position_matching(self, page, pdf_document, text_blocks, page_width, page_height):
        image_list = page.get_images(full=True)
        
        print(f"ğŸ–¼ï¸  PDF ì„ë² ë””ë“œ ì´ë¯¸ì§€: {len(image_list)}ê°œ ë°œê²¬")
        
        # ì´ë¯¸ì§€ ìœ„ì¹˜ ë° í¬ê¸° ì •ë³´ ìˆ˜ì§‘
        image_data = []
        for img_index, img in enumerate(image_list):
            try:
                xref = img[0]
                rects = page.get_image_rects(xref)
                if not rects:
                    continue
                
                rect = rects[0]
                zoom = 2.0
                img_x = rect.x0 * zoom
                img_y = rect.y0 * zoom
                img_w = (rect.x1 - rect.x0) * zoom
                img_h = (rect.y1 - rect.y0) * zoom
                
                # ì‹¤ì œ ì´ë¯¸ì§€ í¬ê¸°ë„ í™•ì¸
                base_image = pdf_document.extract_image(xref)
                image_bytes = base_image["image"]
                pil_image = Image.open(io.BytesIO(image_bytes))
                actual_width, actual_height = pil_image.size
                
                image_data.append({
                    'xref': xref,
                    'index': img_index,
                    'x': img_x,
                    'y': img_y,
                    'w': img_w,
                    'h': img_h,
                    'actual_width': actual_width,
                    'actual_height': actual_height,
                    'area': actual_width * actual_height,
                    'center_x': img_x + img_w/2,
                    'center_y': img_y + img_h/2,
                    'image_bytes': image_bytes,
                    'pil_image': pil_image
                })
                
            except:
                continue
        
        # í¬ê¸° ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬ (í° ì´ë¯¸ì§€ë¶€í„°)
        image_data.sort(key=lambda x: x['area'], reverse=True)
        
        # ì¤‘ë³µ ì œê±°: ë¹„ìŠ·í•œ ìœ„ì¹˜ì˜ ì‘ì€ ì´ë¯¸ì§€ ì œì™¸
        filtered_images = []
        for img in image_data:
            is_duplicate = False
            
            for existing in filtered_images:
                x_diff = abs(img['center_x'] - existing['center_x'])
                y_diff = abs(img['center_y'] - existing['center_y'])
                
                if x_diff < 50 and y_diff < 50 and img['area'] < existing['area']:
                    is_duplicate = True
                    break
            
            if not is_duplicate:
                filtered_images.append(img)
        
        print(f"ğŸ” í•„í„°ë§ í›„: {len(filtered_images)}ê°œ ì´ë¯¸ì§€")
        
        products = []
        seen_hashes = set()
        used_text_blocks = set()
        
        for img_data in filtered_images:
            try:
                width = img_data['actual_width']
                height = img_data['actual_height']
                area = img_data['area']
                pil_image = img_data['pil_image']
                image_bytes = img_data['image_bytes']
                
                # ì¤‘ë³µ ì²´í¬
                import hashlib
                img_hash = hashlib.md5(image_bytes).hexdigest()
                if img_hash in seen_hashes:
                    print(f"  ì´ë¯¸ì§€ {img_data['index'] + 1}: ì¤‘ë³µ ì œì™¸")
                    continue
                seen_hashes.add(img_hash)
                
                # í¬ê¸° í•„í„°
                if width < 150 or height < 150:
                    print(f"  ì´ë¯¸ì§€ {img_data['index'] + 1}: ë„ˆë¬´ ì‘ìŒ ({width}x{height})")
                    continue
                
                if width > 1500 or height > 1500:
                    print(f"  ì´ë¯¸ì§€ {img_data['index'] + 1}: ë„ˆë¬´ í¼ ({width}x{height})")
                    continue
                
                if area < 40000:
                    print(f"  ì´ë¯¸ì§€ {img_data['index'] + 1}: ë©´ì  ë¶€ì¡± ({area})")
                    continue
                
                aspect = width / height
                if not (0.5 <= aspect <= 2.0):
                    print(f"  ì´ë¯¸ì§€ {img_data['index'] + 1}: ë¹„ìœ¨ ë¶€ì í•© ({aspect:.2f})")
                    continue
                
                img_base64 = self._image_to_base64(pil_image)
                
                # í…ìŠ¤íŠ¸ ì°¾ê¸°
                product_info = self._find_text_around_image(img_data, text_blocks, used_text_blocks)
                
                print(f"\n  âœ“ ì´ë¯¸ì§€ {img_data['index'] + 1} â†’ ì œí’ˆ:")
                print(f"    í¬ê¸°: {width}x{height}")
                print(f"    ì œí’ˆëª…: {product_info['name']}")
                print(f"    í…ìŠ¤íŠ¸: {len(product_info['used_indices'])}ê°œ")
                
                products.append({
                    'name': product_info['name'],
                    'specs': product_info['specs'],
                    'details': product_info['details'],
                    'image': img_base64
                })
                
            except Exception as e:
                print(f"  ì´ë¯¸ì§€ ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
                continue
        
        return products
    
    def _find_text_around_image(self, img_data, text_blocks, used_text_blocks):
        """ì´ë¯¸ì§€ ì£¼ë³€ ì „ë°©í–¥ í…ìŠ¤íŠ¸ íƒìƒ‰"""
        if not text_blocks:
            return {
                'name': f'ì œí’ˆ {img_data["index"] + 1}',
                'specs': [],
                'details': [],
                'used_indices': []
            }
        
        img_bottom = img_data['y'] + img_data['h']
        img_center_x = img_data['center_x']
        img_center_y = img_data['center_y']
        img_w = img_data['w']
        img_h = img_data['h']
        
        nearby_texts = []
        
        for idx, block in enumerate(text_blocks):
            if idx in used_text_blocks:
                continue
            
            text_center_x = block['center_x']
            text_center_y = block['center_y']
            text_y = block['y']
            
            # ì•„ë˜ìª½ í…ìŠ¤íŠ¸ (ìµœìš°ì„ )
            vertical_dist = text_y - img_bottom
            if 0 <= vertical_dist <= 200:
                horizontal_dist = abs(text_center_x - img_center_x)
                if horizontal_dist <= img_w * 0.8:
                    nearby_texts.append({
                        'text': block['text'],
                        'priority': 1,
                        'distance': vertical_dist,
                        'x': block['x'],
                        'y': text_y,
                        'index': idx
                    })
                    continue
            
            # ìœ„ìª½ í…ìŠ¤íŠ¸
            vertical_dist_above = img_data['y'] - (text_y + block['h'])
            if 0 <= vertical_dist_above <= 100:
                horizontal_dist = abs(text_center_x - img_center_x)
                if horizontal_dist <= img_w * 0.8:
                    nearby_texts.append({
                        'text': block['text'],
                        'priority': 2,
                        'distance': vertical_dist_above,
                        'x': block['x'],
                        'y': text_y,
                        'index': idx
                    })
                    continue
            
            # ì˜†ìª½ í…ìŠ¤íŠ¸
            if abs(text_center_y - img_center_y) <= img_h * 0.5:
                horizontal_dist = abs(text_center_x - img_center_x)
                if img_w * 0.5 <= horizontal_dist <= img_w * 1.5:
                    nearby_texts.append({
                        'text': block['text'],
                        'priority': 3,
                        'distance': horizontal_dist,
                        'x': block['x'],
                        'y': text_y,
                        'index': idx
                    })
        
        if not nearby_texts:
            return {
                'name': f'ì œí’ˆ {img_data["index"] + 1}',
                'specs': [],
                'details': [],
                'used_indices': []
            }
        
        # ì •ë ¬: ìš°ì„ ìˆœìœ„ â†’ Yì¢Œí‘œ
        nearby_texts.sort(key=lambda t: (t['priority'], t['y'], t['x']))
        nearby_texts = nearby_texts[:12]
        
        # ë¼ì¸ ê·¸ë£¹í™”
        lines = []
        current_line = []
        last_y = -1
        
        for item in nearby_texts:
            if last_y < 0 or abs(item['y'] - last_y) < 30:
                current_line.append(item)
            else:
                if current_line:
                    current_line.sort(key=lambda t: t['x'])
                    lines.append(' '.join([t['text'] for t in current_line]))
                current_line = [item]
            last_y = item['y']
        
        if current_line:
            current_line.sort(key=lambda t: t['x'])
            lines.append(' '.join([t['text'] for t in current_line]))
        
        # ì œí’ˆëª… = ì²« 3ê°œ ë¼ì¸
        product_name = ' '.join(lines[:3]) if len(lines) >= 3 else ' '.join(lines) if lines else f'ì œí’ˆ {img_data["index"] + 1}'
        
        # ìŠ¤í™ ì¶”ì¶œ
        specs = []
        for line in lines[3:]:
            clean = self._clean_text(line)
            if re.search(r'\d+', clean) or any(u in clean for u in ['W', 'mm', 'V', 'K', 'lm', 'COB', 'SMD', 'IP', 'Ã˜']):
                specs.append(clean)
        
        # ì‚¬ìš©ëœ í…ìŠ¤íŠ¸ ë§ˆí‚¹
        for t in nearby_texts:
            used_text_blocks.add(t['index'])
        
        return {
            'name': self._clean_text(product_name),
            'specs': specs[:5],
            'details': [],
            'used_indices': [t['index'] for t in nearby_texts]
        }
    
    def _clean_text(self, text):
        text = re.sub(r'\s+', ' ', text).strip()
        return text[:100] if len(text) > 100 else text
    
    def _image_to_base64(self, image):
        buffered = io.BytesIO()
        image = image.convert('RGB')
        
        if image.width > 400:
            ratio = 400 / image.width
            new_height = int(image.height * ratio)
            image = image.resize((400, new_height), Image.LANCZOS)
        
        image.save(buffered, format="JPEG", quality=90, optimize=True)
        return f"data:image/jpeg;base64,{base64.b64encode(buffered.getvalue()).decode()}"